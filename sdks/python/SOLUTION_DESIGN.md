# Python SDK Type Generation - Solution Design

**Date**: 2025-10-31
**Status**: Design Phase
**Approach**: Post-Processing + Custom Category Generator (following TypeScript patterns)

---

## Problem Summary

Review identified 5 main issues:
1. **Issue 1** (Medium): ~1,760 lines of duplicate type definitions
2. **Issue 2** (High): Numbered class suffixes in category files (Model1, CommonClas1, etc.)
3. **Issue 3** (Low): No import reuse from tidas_data_types.py
4. **Issue 4** (Low): Inconsistent type aliases
5. **Issue 5** (Low): Field naming inconsistency

---

## Solution Architecture

### Phase 1: Post-Processing Script for Entity Files (Solves Issues 1, 3, 4)

**File**: `scripts/postprocess_types.py`

**Strategy**: Modify generated entity files to remove duplicates and add imports from `tidas_data_types.py`

#### Implementation Plan

```python
#!/usr/bin/env python3
"""
Post-process auto-generated Pydantic type files to:
1. Remove duplicate type definitions
2. Add imports from tidas_data_types.py
3. Remove redundant type aliases
4. Clean up code quality issues
"""

import ast
import re
from pathlib import Path
from typing import Set, List, Dict

class TypeFilePostProcessor:
    """Post-process generated Pydantic type files."""

    # Types defined in tidas_data_types.py that should be imported
    BASE_TYPES = {
        'CASNumber', 'FT', 'ST', 'String',
        'MultiLangItem', 'MultiLangItemString', 'MultiLangItemST',
        'StringMultiLang', 'STMultiLang', 'FTMultiLang',
        'Int1', 'Int5', 'Int6', 'LevelType',
        'Perc', 'Real', 'MatR', 'MatV',
        'UUID', 'GlobalReferenceType', 'GlobalReferenceTypeOrArray',
        'GIS', 'Year',
    }

    # Patterns to detect duplicate type definitions
    DUPLICATE_PATTERNS = [
        r'^class (StringMultiLang\d+Item)\(BaseModel\):',
        r'^class (StringMultiLang\d+)\(RootModel\[',
        r'^class (STMultiLang\d+Item)\(BaseModel\):',
        r'^class (STMultiLang\d+)\(RootModel\[',
        r'^class (FTMultiLang\d+Item)\(BaseModel\):',
        r'^class (FTMultiLang\d+)\(RootModel\[',
        r'^class (GlobalReferenceType\d+)\(BaseModel\):',
        r'^class (GlobalReferenceTypeItem)\(BaseModel\):',
        r'^class (CASNumber)\(RootModel\[',
        r'^class (FT)\(RootModel\[',
        r'^class (ST)\(RootModel\[',
        r'^class (Int\d+)\(RootModel\[',
        r'^class (LevelType)\(RootModel\[',
        r'^class (Perc)\(RootModel\[',
        r'^class (MatR)\(RootModel\[',
        r'^class (MatV)\(RootModel\[',
        r'^class (Real)\(RootModel\[',
        r'^class (GIS)\(RootModel\[',
        r'^class (Year)\(RootModel\[',
    ]

    # Redundant alias patterns (e.g., CommonClas5 = CommonClas)
    ALIAS_PATTERN = r'^(\w+) = (\w+)$'

    def __init__(self, file_path: Path):
        self.file_path = file_path
        self.content = file_path.read_text()
        self.lines = self.content.split('\n')
        self.used_base_types: Set[str] = set()
        self.duplicate_classes: Set[str] = set()

    def detect_duplicates(self) -> None:
        """Detect duplicate type definitions."""
        for line in self.lines:
            for pattern in self.DUPLICATE_PATTERNS:
                match = re.match(pattern, line)
                if match:
                    class_name = match.group(1)
                    self.duplicate_classes.add(class_name)

    def detect_used_base_types(self) -> None:
        """Detect which base types from tidas_data_types.py are used."""
        for base_type in self.BASE_TYPES:
            # Check if type is used in the file (as annotation or in Field)
            pattern = rf'\b{base_type}\b'
            if re.search(pattern, self.content):
                self.used_base_types.add(base_type)

    def remove_duplicate_definitions(self) -> List[str]:
        """Remove duplicate class definitions."""
        new_lines = []
        skip_until_next_class = False
        in_duplicate_class = False

        for i, line in enumerate(self.lines):
            # Check if this line starts a duplicate class
            is_duplicate_start = False
            for pattern in self.DUPLICATE_PATTERNS:
                if re.match(pattern, line):
                    is_duplicate_start = True
                    break

            if is_duplicate_start:
                in_duplicate_class = True
                skip_until_next_class = True
                continue

            # Skip lines inside duplicate class
            if skip_until_next_class:
                # Check if we've reached next class or end of duplicate
                if line and not line.startswith(' ') and not line.startswith('\t'):
                    # Check if it's a class definition or top-level statement
                    if line.startswith('class ') or line.startswith('def ') or line.startswith('from ') or line.startswith('import ') or re.match(r'^\w+\s*=', line):
                        skip_until_next_class = False
                        in_duplicate_class = False
                        new_lines.append(line)
                continue

            new_lines.append(line)

        return new_lines

    def add_imports(self, lines: List[str]) -> List[str]:
        """Add imports from tidas_data_types.py."""
        if not self.used_base_types:
            return lines

        # Find where to insert imports (after existing imports)
        import_end_idx = 0
        for i, line in enumerate(lines):
            if line.startswith('from pydantic import') or line.startswith('import '):
                import_end_idx = i + 1
            elif line.strip() == '' and import_end_idx > 0:
                import_end_idx = i + 1
                break

        # Create import statement
        sorted_types = sorted(self.used_base_types)
        import_lines = ['from .tidas_data_types import (']
        for type_name in sorted_types:
            import_lines.append(f'    {type_name},')
        import_lines.append(')')
        import_lines.append('')

        # Insert imports
        new_lines = lines[:import_end_idx] + import_lines + lines[import_end_idx:]
        return new_lines

    def remove_redundant_aliases(self, lines: List[str]) -> List[str]:
        """Remove redundant type aliases like CommonClas5 = CommonClas."""
        new_lines = []
        for line in lines:
            match = re.match(self.ALIAS_PATTERN, line.strip())
            if match:
                alias_name = match.group(1)
                original_name = match.group(2)
                # Skip if it's just renaming with numbers
                if alias_name.rstrip('0123456789') == original_name.rstrip('0123456789'):
                    continue
            new_lines.append(line)
        return new_lines

    def process(self) -> str:
        """Run all post-processing steps."""
        self.detect_duplicates()
        self.detect_used_base_types()

        lines = self.lines
        lines = self.remove_duplicate_definitions()
        lines = self.remove_redundant_aliases(lines)
        lines = self.add_imports(lines)

        return '\n'.join(lines)

    def save(self, output_path: Path = None) -> None:
        """Save processed content."""
        if output_path is None:
            output_path = self.file_path

        processed = self.process()
        output_path.write_text(processed)
        print(f"âœ“ Processed {self.file_path.name}")
        print(f"  - Removed {len(self.duplicate_classes)} duplicate classes")
        print(f"  - Added imports for {len(self.used_base_types)} base types")


def main():
    """Process all entity files."""
    types_dir = Path(__file__).parent.parent / 'src' / 'tidas_sdk' / 'types'

    # Entity files to process (skip category and base types files)
    entity_files = [
        'tidas_contacts.py',
        'tidas_flows.py',
        'tidas_processes.py',
        'tidas_sources.py',
        'tidas_flowproperties.py',
        'tidas_unitgroups.py',
        'tidas_lciamethods.py',
        'tidas_lifecyclemodels.py',
    ]

    for filename in entity_files:
        file_path = types_dir / filename
        if file_path.exists():
            processor = TypeFilePostProcessor(file_path)
            processor.save()
        else:
            print(f"âš ï¸  File not found: {filename}")

    print("\nâœ“ Post-processing completed!")


if __name__ == '__main__':
    main()
```

**Usage**:
```bash
# After running generate_types_v2.py
uv run python scripts/postprocess_types.py
```

---

### Phase 2: Custom Category Generator (Solves Issue 2)

**File**: `scripts/generate_category_types.py`

**Strategy**: Generate clean category files following TypeScript pattern (Union of Literal types)

#### TypeScript Pattern (Reference)

```typescript
// TypeScript category file
export type Contact =
  | { '@level'?: '0'; '@classId'?: '1'; '#text'?: 'Group of organisations, project' }
  | { '@level'?: '0'; '@classId'?: '2'; '#text'?: 'Organisations' }
  | { '@level'?: '1'; '@classId'?: '2.1'; '#text'?: 'Private companies' }
  ...
```

#### Python Equivalent

```python
# Python category file (clean version)
from typing import Literal, TypedDict

class ContactCategory(TypedDict, total=False):
    """Contact category with level, classId, and text."""
    level: Literal['0', '1']
    classId: str
    text: str

# Union type for all contact categories
Contact = Literal[
    '1',    # Group of organisations, project
    '2',    # Organisations
    '2.1',  # Private companies
    '2.2',  # Governmental organisations
    '2.3',  # Non-governmental organisations
    '2.4',  # Other organisations
    '3',    # Working groups within organisation
    '4',    # Persons
    '5',    # Other
]

# Runtime metadata for lookups
CONTACT_CATEGORIES: dict[str, ContactCategory] = {
    '1': {'level': '0', 'classId': '1', 'text': 'Group of organisations, project'},
    '2': {'level': '0', 'classId': '2', 'text': 'Organisations'},
    '2.1': {'level': '1', 'classId': '2.1', 'text': 'Private companies'},
    '2.2': {'level': '1', 'classId': '2.2', 'text': 'Governmental organisations'},
    '2.3': {'level': '1', 'classId': '2.3', 'text': 'Non-governmental organisations'},
    '2.4': {'level': '1', 'classId': '2.4', 'text': 'Other organisations'},
    '3': {'level': '0', 'classId': '3', 'text': 'Working groups within organisation'},
    '4': {'level': '0', 'classId': '4', 'text': 'Persons'},
    '5': {'level': '0', 'classId': '5', 'text': 'Other'},
}

__all__ = ['Contact', 'ContactCategory', 'CONTACT_CATEGORIES']
```

#### Implementation

```python
#!/usr/bin/env python3
"""
Generate clean category type files from JSON schemas.

This generator creates Python category files that follow the clean pattern
used in TypeScript, avoiding numbered class suffixes.
"""

import json
from pathlib import Path
from typing import List, Dict, Any

class CategoryGenerator:
    """Generate clean category type files."""

    def __init__(self, schema_path: Path, output_path: Path):
        self.schema_path = schema_path
        self.output_path = output_path
        self.schema = self.load_schema()
        self.categories = self.extract_categories()

    def load_schema(self) -> Dict[str, Any]:
        """Load JSON schema."""
        with open(self.schema_path) as f:
            return json.load(f)

    def extract_categories(self) -> List[Dict[str, Any]]:
        """Extract category definitions from schema.

        Categories are typically defined as oneOf unions with objects containing:
        - @level (Literal)
        - @classId or @catId (Literal)
        - #text (Literal)
        """
        categories = []

        # Navigate to category definitions (usually in oneOf at root or in $defs)
        if 'oneOf' in self.schema:
            for option in self.schema['oneOf']:
                category = self.extract_category_from_option(option)
                if category:
                    categories.append(category)

        # Also check $defs for category patterns
        if '$defs' in self.schema:
            for def_name, def_schema in self.schema['$defs'].items():
                if 'oneOf' in def_schema:
                    for option in def_schema['oneOf']:
                        category = self.extract_category_from_option(option)
                        if category:
                            categories.append(category)

        return categories

    def extract_category_from_option(self, option: Dict[str, Any]) -> Dict[str, str] | None:
        """Extract category info from a oneOf option."""
        if 'properties' not in option:
            return None

        props = option['properties']

        # Look for @level, @classId/@catId, and #text
        level = None
        class_id = None
        text = None

        if '@level' in props and 'enum' in props['@level']:
            level = props['@level']['enum'][0]

        for key in ['@classId', '@catId']:
            if key in props and 'enum' in props[key]:
                class_id = props[key]['enum'][0]
                break

        if '#text' in props and 'enum' in props['#text']:
            text = props['#text']['enum'][0]

        if level and class_id and text:
            return {
                'level': level,
                'classId': class_id,
                'text': text
            }

        return None

    def get_type_name(self) -> str:
        """Get type name from filename."""
        # e.g., tidas_contacts_category.json -> Contact
        name = self.schema_path.stem.replace('tidas_', '').replace('_category', '')
        return name.title().replace('_', '')

    def get_max_level(self) -> str:
        """Get maximum level value."""
        levels = [cat['level'] for cat in self.categories]
        return max(levels)

    def generate(self) -> str:
        """Generate Python category file content."""
        type_name = self.get_type_name()
        max_level = self.get_max_level()

        lines = [
            '"""',
            f'{type_name} classification categories.',
            '',
            'This file was automatically generated to provide a cleaner API than auto-generated code.',
            'DO NOT manually edit - regenerate using generate_category_types.py',
            '"""',
            '',
            'from typing import Literal, TypedDict',
            '',
            '',
            f'class {type_name}Category(TypedDict, total=False):',
            f'    """{type_name} category with level, classId, and text."""',
            '',
            f"    level: Literal[{', '.join(repr(str(i)) for i in range(int(max_level) + 1))}]",
            '    classId: str',
            '    text: str',
            '',
            '',
            f'# Union type for all {type_name.lower()} categories',
            f'{type_name} = Literal[',
        ]

        # Add category IDs
        for cat in self.categories:
            comment = f"  # {cat['text']}"
            lines.append(f"    '{cat['classId']}',{comment}")

        lines.append(']')
        lines.append('')
        lines.append('')
        lines.append('# Runtime metadata for lookups')
        lines.append(f'{type_name.upper()}_CATEGORIES: dict[str, {type_name}Category] = {{')

        # Add runtime metadata
        for cat in self.categories:
            lines.append(f"    '{cat['classId']}': {{")
            lines.append(f"        'level': '{cat['level']}',")
            lines.append(f"        'classId': '{cat['classId']}',")
            lines.append(f"        'text': '{cat['text']}',")
            lines.append('    },')

        lines.append('}')
        lines.append('')
        lines.append('')
        lines.append(f"__all__ = ['{type_name}', '{type_name}Category', '{type_name.upper()}_CATEGORIES']")
        lines.append('')

        return '\n'.join(lines)

    def save(self) -> None:
        """Generate and save category file."""
        content = self.generate()
        self.output_path.write_text(content)
        print(f"âœ“ Generated {self.output_path.name}")


def main():
    """Generate all category files."""
    schemas_dir = Path(__file__).parent.parent.parent / 'tidas-tools' / 'src' / 'tidas_tools' / 'tidas' / 'schemas'
    output_dir = Path(__file__).parent.parent / 'src' / 'tidas_sdk' / 'types'

    category_files = [
        'tidas_contacts_category.json',
        'tidas_flows_elementary_category.json',
        'tidas_flows_product_category.json',
        'tidas_processes_category.json',
        'tidas_flowproperties_category.json',
        'tidas_lciamethods_category.json',
        'tidas_locations_category.json',
        'tidas_sources_category.json',
        'tidas_unitgroups_category.json',
    ]

    for filename in category_files:
        schema_path = schemas_dir / filename
        output_path = output_dir / filename.replace('.json', '.py')

        if schema_path.exists():
            try:
                generator = CategoryGenerator(schema_path, output_path)
                generator.save()
            except Exception as e:
                print(f"âœ— Error generating {filename}: {e}")
        else:
            print(f"âš ï¸  Schema not found: {filename}")

    print("\nâœ“ Category generation completed!")


if __name__ == '__main__':
    main()
```

**Usage**:
```bash
uv run python scripts/generate_category_types.py
```

---

## Complete Workflow

### Updated `generate_types_v2.py`

Modify to automatically run post-processing:

```python
# At the end of generate_types_v2.py
def main() -> int:
    # ... existing code ...

    # Post-process entity files
    print("\n" + "="*60)
    print("Running post-processing...")
    print("="*60)
    subprocess.run([sys.executable, "scripts/postprocess_types.py"], check=True)

    # Generate clean category files
    print("\n" + "="*60)
    print("Generating clean category files...")
    print("="*60)
    subprocess.run([sys.executable, "scripts/generate_category_types.py"], check=True)

    # Return exit code
    return 1 if stats["errors"] > 0 else 0
```

### Single Command

```bash
# Regenerate all types with automatic cleanup
uv run python scripts/generate_types_v2.py --force
```

This will:
1. Generate entity files with datamodel-code-generator
2. Automatically remove duplicates and add imports
3. Generate clean category files
4. All in one command

---

## Benefits of This Approach

### âœ… Advantages

1. **Follows TypeScript patterns** - Consistent cross-language SDK design
2. **Automated** - No manual file editing required
3. **Maintainable** - Clear separation of concerns
4. **Incremental** - Can be adopted step-by-step
5. **Preserves type safety** - All types remain strictly typed
6. **Reduces duplication** - ~1,760 lines saved
7. **Improves readability** - No more Model1, Model2, etc.

### ðŸ“Š Expected Results

**Before**:
- 19 files, ~8,500 lines total
- ~1,760 lines of duplication
- Category files with Model1..Model19 classes
- No import reuse

**After**:
- 19 files, ~6,740 lines total (21% reduction)
- Zero duplication
- Clean category files with Literal types
- Proper import management

---

## Testing Strategy

```python
# tests/test_generated_types.py
"""Test generated type files."""

def test_all_types_importable():
    """All types can be imported."""
    from tidas_sdk.types import (
        Contact, Flow, Process, Source,
        FlowProperty, UnitGroup, LCIAMethod, LifeCycleModel
    )
    assert Contact is not None

def test_base_types_reused():
    """Entity files import from tidas_data_types."""
    from tidas_sdk.types import tidas_contacts

    # Check that import statement exists
    source = inspect.getsource(tidas_contacts)
    assert 'from .tidas_data_types import' in source

def test_no_duplicate_definitions():
    """No duplicate class definitions exist."""
    from tidas_sdk.types import tidas_contacts

    source = inspect.getsource(tidas_contacts)
    # Should not contain StringMultiLang1Item class
    assert 'class StringMultiLang1Item' not in source

def test_category_files_clean():
    """Category files use Literal types."""
    from tidas_sdk.types.tidas_contacts_category import Contact, CONTACT_CATEGORIES

    # Should be Literal type (has __args__)
    assert hasattr(Contact, '__args__')

    # Should have metadata dict
    assert isinstance(CONTACT_CATEGORIES, dict)
    assert '1' in CONTACT_CATEGORIES
```

---

## Implementation Timeline

### Week 1: Post-Processing Script
- [ ] Implement `postprocess_types.py`
- [ ] Test on 2-3 entity files
- [ ] Verify mypy --strict still passes
- [ ] Run full test suite

### Week 2: Category Generator
- [ ] Implement `generate_category_types.py`
- [ ] Generate 3 high-priority categories
- [ ] Test category type usage
- [ ] Document patterns

### Week 3: Integration
- [ ] Integrate both scripts into generate_types_v2.py
- [ ] Generate all 8 category files
- [ ] Update __init__.py exports
- [ ] Full validation

### Week 4: Validation & Documentation
- [ ] Add comprehensive tests
- [ ] Update documentation
- [ ] Create migration guide
- [ ] Performance benchmarks

---

## Risk Mitigation

### Risk 1: Post-processing breaks type checking

**Mitigation**:
- Run mypy --strict after every change
- Keep backup of original files
- Implement incremental rollout

### Risk 2: Category generator misses edge cases

**Mitigation**:
- Start with manual tidas_contacts_category.py as reference
- Generate one file at a time
- Compare with TypeScript output
- Validate against JSON schemas

### Risk 3: Import cycles

**Mitigation**:
- Use TYPE_CHECKING imports where needed
- Follow dependency order (base types â†’ categories â†’ entities)
- Test import order thoroughly

---

## Success Criteria

âœ… All 19 files pass mypy --strict
âœ… ~1,760 lines of duplication removed
âœ… Zero numbered class suffixes (Model1, CommonClas1, etc.)
âœ… All base types imported from tidas_data_types.py
âœ… Category files use clean Literal patterns
âœ… All existing tests pass
âœ… New validation tests pass
âœ… Generation time remains < 15 seconds

---

## Future Enhancements

1. **Custom JSON Schema â†’ Pydantic converter** (like TypeScript's custom converter)
2. **Runtime validation helpers** (like TypeScript's Zod schemas)
3. **Multi-language helper classes** (like TypeScript's MultiLangArray)
4. **Automatic constraint validation** (pattern, min/max, etc.)
5. **Schema evolution tracking** (detect breaking changes)

---

## Conclusion

This solution design follows TypeScript SDK patterns while leveraging Python's strengths (Pydantic, type hints). The two-phase approach (post-processing + category generator) is:

- **Practical**: Uses existing tools where possible
- **Maintainable**: Clear separation of generation and cleanup
- **Scalable**: Can be enhanced incrementally
- **Automated**: Single command regenerates everything

The design solves all 5 identified issues while maintaining 100% type safety and improving code quality by 21% (line reduction).
